{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea71e846",
   "metadata": {},
   "source": [
    "# Inroduction\n",
    "\n",
    "This notebook demonstrates a toy scenario of a network with users, systems and resources, and how structural information can be identified using graph explainers in order to make strategic red-team and blue-team decisions.\n",
    "\n",
    "The network graph is built programmatically and randomly based on various parameters. The graph is homogeneous; metadata stores the node type (user, system, resource).\n",
    "\n",
    "The graph learning in this notebook is transductive, meaning it's learning about a single given graph. That was chosen for simplicity. However, the code could be extended to be inductive by training on many randomly generated graphs. The GraphSAGE is a framework appropriate for inductive learning on graphs, and is one of the model types used here.\n",
    "\n",
    "Importantly, in the generated graphs there is a notion of compromised user(s) and high-value resources. From a red-teaming perspective, a compromised user might be a known target, and a high-value resource might be identified as high-value after initial reconnaissance.\n",
    "\n",
    "For the purposes of this toy example, the compromised user label provides a classification problem for transductive learning. This is useful because it provides a way to learn node vectors; however, node vectors could be learned in an unsupervised context as well; for example, using Deep Graph Infomax (DGI) which is implemented in pytorch_geometric, as is GraphSAGE.\n",
    "\n",
    "After doing transductive learning on the generated graph using a 2-layer GNN, we then use the GNNExplainer, also from pytorch_geomtric, to identify nodes that: (1) contribute most to the target node’s prediction, (2) are bottlenecks in information flow, (3) determine classification outcomes (e.g., malicious vs. benign).\n",
    "\n",
    "It works by turning edges and features off, and the ones it can’t remove without changing the model’s answer are the important parts of the graph.\n",
    "\n",
    "So, overall steps taken are:\n",
    "1) build a random graph\n",
    "2) learn to classify user nodes in the graph by risk\n",
    "3) run the graph explainer to identify salient structure in the graph\n",
    "4) extract the explainer's edge info about a high-risk user and high-value resource(s)\n",
    "5) call OpenAI API to translate the explainer details into red and blue team recommendations\n",
    "6) visualize the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4120883",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.explain  import Explainer, GNNExplainer\n",
    "from torch_geometric.explain.config import ModelConfig, ModelMode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72b0c47",
   "metadata": {},
   "source": [
    "## Build the toy \"access\" graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "759b7827",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random_access_graph import generate_access_graph\n",
    "\n",
    "# build a random graph\n",
    "data, meta = generate_access_graph(\n",
    "    n_users=8, n_systems=6, n_resources=10,\n",
    "    p_login=0.3, p_lateral=0.04, p_sys_access=0.4,\n",
    "    p_cross_user_cluster=0.15, n_user_clusters=3,\n",
    "    high_value_ratio=0.15,\n",
    "    seed=99\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8610b561",
   "metadata": {},
   "source": [
    "## Create a tiny GCN or GraphSAGE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c2afcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gnn_factory import build_gnn\n",
    "\n",
    "MODEL_NAME = \"sage\"          # <── swap \"gcn\"  /  \"sage\"\n",
    "model = build_gnn(MODEL_NAME,\n",
    "                  in_dim=3,\n",
    "                  hidden=32,\n",
    "                  n_classes=2)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "for _ in range(200):\n",
    "    opt.zero_grad()\n",
    "    out  = model(data.x, data.edge_index)\n",
    "    loss = F.cross_entropy(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward(); opt.step()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e4a140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single-graph TRAIN accuracy (1.0 here because the only malicious user is in train_mask).\n",
    "# The score is not a useful metric; we train purely to obtain embeddings\n",
    "# that GNNExplainer will analyse.  Unsupervised objectives (e.g. DGI) could serve the\n",
    "# same purpose if no labels were available.\n",
    "with torch.no_grad():\n",
    "    logits = model(data.x, data.edge_index)\n",
    "    pred   = logits.argmax(dim=1)\n",
    "    acc    = (pred[data.train_mask] == data.y[data.train_mask]).float().mean()\n",
    "print(f\"Train accuracy: {acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe55dac1",
   "metadata": {},
   "source": [
    "## Run GNNExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e746b23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = Explainer(\n",
    "    model=model,\n",
    "    algorithm=GNNExplainer(epochs=500, lr=0.005),        # more epochs → clearer masks\n",
    "    explanation_type='model',\n",
    "    node_mask_type='attributes',\n",
    "    edge_mask_type='object',\n",
    "    model_config=ModelConfig(\n",
    "        mode=ModelMode.multiclass_classification,\n",
    "        task_level='node',\n",
    "        return_type='raw',                     # logits\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da937eb",
   "metadata": {},
   "source": [
    "## Calculate risk scores and braodcast scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da7dca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_tabular import get_node_types\n",
    "from rank_user_compromise import rank_users, broadcast_scores\n",
    "\n",
    "top_users = rank_users(data, model, k=3, node_types=get_node_types(meta))\n",
    "print(\"=== highest-risk users ===\")\n",
    "print(top_users)\n",
    "\n",
    "bc = broadcast_scores(data, explainer, top_users[\"node_id\"])\n",
    "print(\"\\n=== broadcast score ===\")\n",
    "print(bc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26b6284a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for now, only keep the explaination for the user node with highest risk score\n",
    "node_ids = top_users[\"node_id\"].tolist()\n",
    "for node_id in top_users[\"node_id\"]:\n",
    "    explanation = explainer(data.x, data.edge_index, index=node_id)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ee5aff",
   "metadata": {},
   "source": [
    "# Review the explanation and related data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593ebf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the importance of the features for the high risk user node\n",
    "feat_names = meta[\"data_feature_names\"]\n",
    "row = explanation.node_mask[node_id]           # (3,) tensor\n",
    "for w, n in sorted(zip(row.tolist(), feat_names), reverse=True):\n",
    "    print(f\"{n:<15} {w:6.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e481bae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at influential edges related to the high risk user node (not necessarily connected to that node)\n",
    "\n",
    "print(f\"\\nTop-5 influential edges for node {node_id}:\")\n",
    "edge_scores = explanation.edge_mask\n",
    "edge_idx_T  = data.edge_index.t()\n",
    "top = torch.topk(edge_scores, 5)\n",
    "for s, idx in zip(top.values, top.indices):\n",
    "    u, v = edge_idx_T[idx].tolist()\n",
    "    print(f\"{u:>2} → {v:<2}  score={s:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53672db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_tabular import TabularData, NodeCategories\n",
    "\n",
    "# Get tabular data for easier, further inspection\n",
    "node_categories = NodeCategories(meta)\n",
    "tabular_data = TabularData(data, meta, explanation, node_id)\n",
    "node_info = tabular_data.get_per_node_info()\n",
    "edge_info = tabular_data.get_per_edge_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e5665f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(node_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4412e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(edge_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e21eac3",
   "metadata": {},
   "source": [
    "## Define Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132636af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to be able to exploit the explainer's info about the graph.\n",
    "# Above we looked at high risk user info. Now let's look at high value resources.\n",
    "# Then we'll get actionable insights for both.\n",
    "\n",
    "# 1) decide resource target(s)\n",
    "targets = meta.get('high_value', []) or meta['resources']\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751fcba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_tabular import explain_resource_paths\n",
    "\n",
    "# 2) for each high-value resource, get the top K conduit edges\n",
    "all_hv_reports = {}\n",
    "for rid in targets:\n",
    "    hv_df, hv_nodes = explain_resource_paths(data, meta, explainer, rid, top_k=10)\n",
    "    all_hv_reports[rid] = hv_df        # store for dashboards / bullets\n",
    "    print(f\"\\nTop paths to resource {rid}\")\n",
    "    print(hv_df[['src','dst','importance','kind']])\n",
    "\n",
    "# also, get the top K user edges\n",
    "topk_edges = tabular_data.get_topk_edges()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f3ac8f",
   "metadata": {},
   "source": [
    "## Create an LLM explanation summary from top edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b09c018",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_llm_explain import explain_edges_with_llm, build_edge_sentence_fn\n",
    "import json\n",
    "\n",
    "to_sentence = build_edge_sentence_fn(node_categories.users, node_categories.systems, node_categories.resources)\n",
    "\n",
    "# make API call to LMM to get resource and user edge actions\n",
    "resource_bullets = \"\\n\".join(\"• \"+to_sentence(r) for _, r in hv_df.iterrows())\n",
    "user_bullets = \"\\n\".join(\"• \"+to_sentence(r) for _, r in topk_edges.iterrows())\n",
    "report_resource = explain_edges_with_llm(resource_bullets)\n",
    "report_user = explain_edges_with_llm(user_bullets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5117a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Resource Report ===\")\n",
    "print(resource_bullets)\n",
    "print(\"-\"*100)\n",
    "print(json.dumps(report_resource, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a625865",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== User Report ===\")\n",
    "print(user_bullets)\n",
    "print(\"-\"*100)\n",
    "print(json.dumps(report_user, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299ec5fa",
   "metadata": {},
   "source": [
    "## Visualise the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efa00ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualize_graph import visualize_graph\n",
    "visualize_graph(data, meta, top_users, bc)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
